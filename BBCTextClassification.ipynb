{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwordsList=stopwords.words('english')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "********\n",
    "\n",
    "    -Reading the text documents.\n",
    "    -Preparing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get a list of all txt files in target directory for a particular category\n",
    "tags=[r'\\business',r'\\entertainment',r'\\politics',r'\\sport',r'\\tech']\n",
    "length=[0,0,0,0,0]\n",
    "filesList=[]\n",
    "text=[]\n",
    "for i in range(0,5):\n",
    "    my_dir = r\"C:\\Users\\inbox\\OneDrive\\Documents\\bbc\"\n",
    "    os.chdir(my_dir+tags[i])\n",
    "# Step 2: Build up list of files:\n",
    "    for files in glob.glob(\"*.txt\"):\n",
    "        fileName, fileExtension = os.path.splitext(files)\n",
    "        filesList.append(files) #filename with extension  \n",
    "        length[i]+=1    \n",
    "    for j in range(len(filesList)-length[i],len(filesList)):\n",
    "            file1 = open(filesList[j])\n",
    "            text.append(file1.read())              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DocumentID                                               Text    Labels\n",
       "0         T1  Ad sales boost Time Warner profit\\n\\nQuarterly...  Business\n",
       "1         T2  Dollar gains on Greenspan speech\\n\\nThe dollar...  Business\n",
       "2         T3  Yukos unit buyer faces loan claim\\n\\nThe owner...  Business\n",
       "3         T4  High fuel prices hit BA's profits\\n\\nBritish A...  Business\n",
       "4         T5  Pernod takeover talk lifts Domecq\\n\\nShares in...  Business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing the final dataframe\n",
    "labelMarker=[]\n",
    "labelMarker.append(length[0])\n",
    "labelMarker.append(length[0]+length[1])\n",
    "labelMarker.append(length[0]+length[1]+length[2])\n",
    "labelMarker.append(length[0]+length[1]+length[2]+length[3])\n",
    "labelMarker.append(length[0]+length[1]+length[2]+length[3]+length[4])\n",
    "# labelMarker has been updated to assign the labels correctly\n",
    "df=pd.DataFrame()\n",
    "labels=[]\n",
    "ids=[]\n",
    "for i in range(0,len(text)):\n",
    "    ids.append(\"T\"+str(i+1))\n",
    "    if i<labelMarker[0]:\n",
    "        labels.append(\"Business\")\n",
    "    elif i>=labelMarker[0] and i<labelMarker[1]:\n",
    "        labels.append(\"Entertainment\")\n",
    "    elif i>=labelMarker[1] and i<labelMarker[2]:\n",
    "        labels.append(\"Politics\")\n",
    "    elif i>=labelMarker[2] and i<labelMarker[3]:\n",
    "        labels.append(\"Sports\")\n",
    "    else:\n",
    "        labels.append(\"Technology\")\n",
    "df['DocumentID']=ids\n",
    "df['Text']=text\n",
    "df['Labels']=labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "********\n",
    "\n",
    "    -Checking for null columns.\n",
    "    -Checking for column with empty strings.\n",
    "    -Stripping white spaces at beginning and end from the label names.\n",
    "    -Distribution of various categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records is 2225\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of records is {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- No column has null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentID    False\n",
       "Text          False\n",
       "Labels        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No column has null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sports           511\n",
       "Business         510\n",
       "Politics         417\n",
       "Technology       401\n",
       "Entertainment    386\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********\n",
    "<strong>Distribution Analysis</strong>\n",
    "\n",
    "    - Category with very less data points will be considered as noise by model but there are no such categories in our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "***********\n",
    "\n",
    "    -Helper functions\n",
    "    -Data preprocessing using these functions\n",
    "    -Distribution of Length of text documents for a optimal selection of max length while building a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing anything followed by a @\n",
    "def remove_mention(x):\n",
    "    return re.sub(r'@[A-Za-z0-9]+','',x)\n",
    "\n",
    "# Removing the urls\n",
    "def remove_urls(x):\n",
    "    return re.sub('https?://[A-Za-z0-9./]+','',x)\n",
    "\n",
    "# Removing the Numbers\n",
    "def remove_hastagNumbers(x):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "\n",
    "# Split text at CamelCase\n",
    "def split_uppercase(x):\n",
    "    return str(\" \".join([\" \".join(re.split(\"([A-Z]{1}[a-z]+)\",word)) for word in x.split(' ')]))\n",
    "    \n",
    "# Converting text in lowercase\n",
    "def LowerCase(x):\n",
    "    return str(x.lower())\n",
    "\n",
    "# Removing stopwords\n",
    "def StopwordsRemoval(x):\n",
    "    return str(' '.join([each if each not in stopwordsList else '' for each in x.split(' ')]))\n",
    "\n",
    "# Removing multiple white spaces from the text\n",
    "def RemoveMultipleWhiteSpaces(x):\n",
    "    FILTER_MULTIPLE_WHITESPACES = \"\\s\\s+\"\n",
    "    return re.sub(FILTER_MULTIPLE_WHITESPACES,' ',x)\n",
    "\n",
    "# Strip spaces at the end and the starting\n",
    "def toStripWhiteSpaces(x):\n",
    "    return x.strip()\n",
    "\n",
    "# To remove new line characters from our text\n",
    "def toStripNewLines(x):\n",
    "    return x.rstrip('\\r\\n')\n",
    "\n",
    "# Function for calling all the other functions\n",
    "def preprocess(x):\n",
    "    return toStripNewLines(toStripWhiteSpaces(RemoveMultipleWhiteSpaces(StopwordsRemoval(LowerCase(split_uppercase(remove_hastagNumbers(remove_urls(remove_mention(x)))))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Helper Functions for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the text by using helper functions\n",
    "df['preprocessed_description']=df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing text with the above defined helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************\n",
    "<strong>Tokenization</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for word tokenizer\n",
    "def tokenization(words):\n",
    "    return(word_tokenize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above defined tokenization function\n",
    "df['preprocessed_description']=df['preprocessed_description'].apply(tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<strong>Stemming</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for stemming\n",
    "def stemming(words):\n",
    "    porter = PorterStemmer()\n",
    "    for i,word in enumerate(words):\n",
    "        words[i]=porter.stem(word)\n",
    "    return words   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above defined stemming function \n",
    "df['preprocessed_description']=df['preprocessed_description'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<strong>Lemmatization</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for lemmatization\n",
    "def lemmatization(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i,word in enumerate(words):\n",
    "        words[i]=lemmatizer.lemmatize(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above defined lemmatization function \n",
    "df['preprocessed_description']=df['preprocessed_description'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [ad, sale, boost, time, warner, profit, quarte...\n",
       "1       [dollar, gain, greenspan, speech, dollar, hit,...\n",
       "2       [yuko, unit, buyer, face, loan, claim, owner, ...\n",
       "3       [high, fuel, price, hit, ba, profit, british, ...\n",
       "4       [pernod, takeov, talk, lift, domecq, share, uk...\n",
       "5       [japan, narrowli, escap, recess, japan, econom...\n",
       "6       [job, growth, still, slow, u, u, creat, fewer,...\n",
       "7       [india, call, fair, trade, rule, india, attend...\n",
       "8       [ethiopia, crop, product, ethiopia, produc, mi...\n",
       "9       [court, reject, bn, tobacco, case, u, govern, ...\n",
       "10      [ask, jeev, tip, onlin, ad, reviv, ask, jeev, ...\n",
       "11      [indonesian, face, fuel, price, rise, indonesi...\n",
       "12      [peugeot, deal, boost, mitsubishi, struggl, ja...\n",
       "13      [telegraph, newspap, axe, job, daili, sunday, ...\n",
       "14      [air, passeng, win, new, eu, right, air, passe...\n",
       "15      [china, keep, tight, rein, credit, china, effo...\n",
       "16      [parmalat, boast, doubl, profit, parmalat, ita...\n",
       "17      [india, rupe, hit, five, year, high, india, ru...\n",
       "18      [india, widen, access, telecom, india, rais, l...\n",
       "19      [call, centr, user, lose, patienc, custom, tri...\n",
       "20      [rank, set, sell, film, unit, leisur, group, r...\n",
       "21      [sluggish, economi, hit, german, job, number, ...\n",
       "22      [mix, signal, french, economi, french, economi...\n",
       "23      [u, trade, gap, hit, record, gap, u, export, i...\n",
       "24      [yuko, lose, u, bankruptci, battl, judg, dismi...\n",
       "25      [safeti, alert, gm, recal, car, world, biggest...\n",
       "26      [steel, firm, cut, job, mittal, steel, one, wo...\n",
       "27      [strong, demand, trigger, oil, ralli, crude, o...\n",
       "28      [uk, firm, face, venezuelan, land, row, venezu...\n",
       "29      [soar, oil, hit, world, economi, soar, cost, o...\n",
       "                              ...                        \n",
       "2195    [text, messag, record, smash, uk, mobil, owner...\n",
       "2196    [softwar, watch, work, softwar, monitor, everi...\n",
       "2197    [commodor, find, new, lea, life, famou, commod...\n",
       "2198    [cab, collect, mountain, mobil, gadget, cheape...\n",
       "2199    [mobil, bet, pocket, offic, mobil, launch, lat...\n",
       "2200    [california, set, fine, spywar, maker, comput,...\n",
       "2201    [mobil, tv, tip, one, watch, scandinavian, kor...\n",
       "2202    [appl, laptop, greatest, gadget, appl, powerbo...\n",
       "2203    [sun, offer, process, hour, sun, microsystem, ...\n",
       "2204    [kenyan, school, turn, handheld, mbita, point,...\n",
       "2205    [tough, rule, rington, seller, firm, flout, ru...\n",
       "2206    [mobil, music, challeng, pod, age, nokia, micr...\n",
       "2207    [china, ripe, medium, explos, asia, set, drive...\n",
       "2208    [beckham, viru, spot, net, viru, writer, trade...\n",
       "2209    [video, phone, act, date, tool, technolog, e, ...\n",
       "2210    [progress, new, internet, domain, earli, net, ...\n",
       "2211    [camera, phone, must, have, four, time, mobil,...\n",
       "2212    [mobil, multimedia, slow, catch, doubt, mobil,...\n",
       "2213    [anti, spam, law, bite, spammer, hard, net, se...\n",
       "2214    [peer, peer, net, stay, peer, peer, p, p, netw...\n",
       "2215    [broadband, fuel, onlin, express, fast, web, a...\n",
       "2216    [savvi, searcher, fail, spot, ad, internet, se...\n",
       "2217    [tv, futur, phone, line, internet, tv, talk, s...\n",
       "2218    [cebit, fever, take, hanov, thousand, product,...\n",
       "2219    [new, consol, promis, big, problem, make, game...\n",
       "2220    [bt, program, beat, dialler, scam, bt, introdu...\n",
       "2221    [spam, e, mail, tempt, net, shopper, comput, u...\n",
       "2222    [care, code, new, european, direct, could, put...\n",
       "2223    [u, cyber, secur, chief, resign, man, make, su...\n",
       "2224    [lose, onlin, game, onlin, role, play, game, t...\n",
       "Name: preprocessed_description, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************\n",
    "<strong>Feature Engineering</strong>\n",
    "    \n",
    "    - Tranforming the data into features using tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the term frequency for each word in a document\n",
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the inverse document frequency\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the tfidf\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the wordset containing all the words in the corpus\n",
    "wordSet=set()\n",
    "for bow in df['preprocessed_description']:\n",
    "    wordSet=wordSet|set(bow)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18839"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a list of dictionary having a word in a document as key and its count as the value\n",
    "wordDictList=[]\n",
    "for bow in df['preprocessed_description']:\n",
    "    wordDict = dict.fromkeys(wordSet, 0) \n",
    "    for word in bow:\n",
    "        wordDict[word]+=1\n",
    "    wordDictList.append(wordDict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a list of term frequency for the documents\n",
    "tflist=[]\n",
    "for i,bow in enumerate(df['preprocessed_description']):\n",
    "    tfDict=computeTF(wordDictList[i], bow)\n",
    "    tflist.append(tfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the inverse document frequency\n",
    "idfs = computeIDF(wordDictList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a list of tfidf for the documents or preprocessed description\n",
    "tfIdfList=[]\n",
    "for i,tf in enumerate(tflist):\n",
    "    tfidf = computeTFIDF(tflist[i], idfs)\n",
    "    tfIdfList.append(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a dataframe for the above calculated tfidf\n",
    "df_tf_idf=pd.DataFrame(tfIdfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aadc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaltra</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aan</th>\n",
       "      <th>aara</th>\n",
       "      <th>aarhu</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zornotza</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zuton</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18839 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aac  aadc  aaliyah  aaltra  aamir  aan  aara  aarhu  ...  zoom  \\\n",
       "0  0.0  0.0  0.0   0.0      0.0     0.0    0.0  0.0   0.0    0.0  ...   0.0   \n",
       "1  0.0  0.0  0.0   0.0      0.0     0.0    0.0  0.0   0.0    0.0  ...   0.0   \n",
       "2  0.0  0.0  0.0   0.0      0.0     0.0    0.0  0.0   0.0    0.0  ...   0.0   \n",
       "3  0.0  0.0  0.0   0.0      0.0     0.0    0.0  0.0   0.0    0.0  ...   0.0   \n",
       "4  0.0  0.0  0.0   0.0      0.0     0.0    0.0  0.0   0.0    0.0  ...   0.0   \n",
       "\n",
       "   zooropa  zornotza  zorro  zubair  zuluaga  zurich  zuton  zvonareva  \\\n",
       "0      0.0       0.0    0.0     0.0      0.0     0.0    0.0        0.0   \n",
       "1      0.0       0.0    0.0     0.0      0.0     0.0    0.0        0.0   \n",
       "2      0.0       0.0    0.0     0.0      0.0     0.0    0.0        0.0   \n",
       "3      0.0       0.0    0.0     0.0      0.0     0.0    0.0        0.0   \n",
       "4      0.0       0.0    0.0     0.0      0.0     0.0    0.0        0.0   \n",
       "\n",
       "   zvyagintsev  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 18839 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************\n",
    "<strong>Encoding</strong>\n",
    "    \n",
    "    - Label encoding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode the target variable\n",
    "finalDf=df\n",
    "Encoder = LabelEncoder()\n",
    "finalDf['encoded_labels'] = Encoder.fit_transform(finalDf['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>encoded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[ad, sale, boost, time, warner, profit, quarte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[dollar, gain, greenspan, speech, dollar, hit,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[yuko, unit, buyer, face, loan, claim, owner, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[high, fuel, price, hit, ba, profit, british, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[pernod, takeov, talk, lift, domecq, share, uk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DocumentID                                               Text    Labels  \\\n",
       "0         T1  Ad sales boost Time Warner profit\\n\\nQuarterly...  Business   \n",
       "1         T2  Dollar gains on Greenspan speech\\n\\nThe dollar...  Business   \n",
       "2         T3  Yukos unit buyer faces loan claim\\n\\nThe owner...  Business   \n",
       "3         T4  High fuel prices hit BA's profits\\n\\nBritish A...  Business   \n",
       "4         T5  Pernod takeover talk lifts Domecq\\n\\nShares in...  Business   \n",
       "\n",
       "                            preprocessed_description  encoded_labels  \n",
       "0  [ad, sale, boost, time, warner, profit, quarte...               0  \n",
       "1  [dollar, gain, greenspan, speech, dollar, hit,...               0  \n",
       "2  [yuko, unit, buyer, face, loan, claim, owner, ...               0  \n",
       "3  [high, fuel, price, hit, ba, profit, british, ...               0  \n",
       "4  [pernod, takeov, talk, lift, domecq, share, uk...               0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting\n",
    "\n",
    "    - Splitting the data in train test sample.\n",
    "    - Using stratified sampling to check the accuracy for each Department label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(df_tf_idf,finalDf['encoded_labels'].values,test_size=0.2,random_state=0,stratify=finalDf['encoded_labels'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "<strong>Building a Logistic Regresion model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "clf = linear_model.LogisticRegression(random_state=0,solver='sag',multi_class='multinomial') \n",
    "clf.fit(Xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random state has been set to produce reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************\n",
    "<strong>Evaluating the model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  66.51685393258427\n"
     ]
    }
   ],
   "source": [
    "# Use accuracy_score function to get the accuracy\n",
    "y_predicted_test=clf.predict(Xtest)\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(y_predicted_test, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.56      1.00      0.72       102\n",
      "Entertainment       0.96      0.32      0.49        77\n",
      "     Politics       1.00      0.44      0.61        84\n",
      "       Sports       0.60      1.00      0.75       102\n",
      "   Technology       1.00      0.38      0.55        80\n",
      "\n",
      "     accuracy                           0.67       445\n",
      "    macro avg       0.82      0.63      0.62       445\n",
      " weighted avg       0.80      0.67      0.63       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(ytest, y_predicted_test, target_names=Encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "<strong>Using Random Forest Classification</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Creating a Random forest object with a random state for reproducible results\n",
    "clf = RandomForestClassifier(max_depth=25,n_estimators=19, random_state=0)\n",
    "#Training the model on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "y_predicted_test = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best accuracy is obtained at n_estimators=19 and max_depth=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************\n",
    "<strong>Evaluating the model</strong> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score ->  96.17977528089887\n"
     ]
    }
   ],
   "source": [
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Random Forest Accuracy Score -> \",accuracy_score(y_predicted_test, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.97      0.90      0.93       102\n",
      "Entertainment       0.99      0.99      0.99        77\n",
      "     Politics       0.92      0.95      0.94        84\n",
      "       Sports       0.99      1.00      1.00       102\n",
      "   Technology       0.94      0.97      0.96        80\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.96      0.96      0.96       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(ytest, y_predicted_test, target_names=Encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "<strong>Using KNN Classification</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K fold cross validation to find the optimum value of k\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "scores = cross_val_score(knn, Xtrain, ytrain, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67877095 0.60504202 0.57142857 0.57746479 0.58923513]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6043882908334224\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the mean cross validation score for k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# choose k between 1 to 10\n",
    "k_range = range(1, 10)\n",
    "k_scores = []\n",
    "# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, Xtrain, ytrain, cv=5, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "# plot to see clearly\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This plot shows that best accuracy will be obtained at k=1(i.e the boundaries between classes are very clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(Xtrain, ytrain)\n",
    "# predict the labels on validation dataset\n",
    "y_predicted_test = classifier.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************\n",
    "<strong>Evaluating the model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score ->  76.85393258426966\n"
     ]
    }
   ],
   "source": [
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"KNN Accuracy Score -> \",accuracy_score(y_predicted_test, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.90      0.56      0.69       102\n",
      "Entertainment       0.89      0.84      0.87        77\n",
      "     Politics       0.58      0.95      0.72        84\n",
      "       Sports       1.00      0.74      0.85       102\n",
      "   Technology       0.68      0.81      0.74        80\n",
      "\n",
      "     accuracy                           0.77       445\n",
      "    macro avg       0.81      0.78      0.77       445\n",
      " weighted avg       0.82      0.77      0.77       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(ytest, y_predicted_test, target_names=Encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "************************\n",
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong>The three model approaches</strong>\n",
    "    \n",
    "  <i>Random Forest Model</i><br>\n",
    "\n",
    "<strong>Pros</strong><br>\n",
    "- As the data is less this model will outperform all the other models providing a accuracy of <strong>96.17%</strong>.\n",
    "- The predictive performance can compete with the best supervised learning algorithms.<br>\n",
    "\n",
    "<strong>Cons</strong><br> \n",
    "- An ensemble model is inherently less interpretable than an individual decision tree.\n",
    "- Training a large number of deep trees can have high computational costs (but can be parallelized) and use a lot of memory.<br><br>\n",
    " \n",
    " \n",
    "<i>Logistic Regression</i><br>\n",
    "\n",
    "<strong>Pros</strong><br>\n",
    "- It is easy to understand and it can also be trained on small dataset. <br>\n",
    "\n",
    "<strong>Cons</strong><br> \n",
    "- The model is highly scalable although it is giving a accuracy of just <strong>66.51%</strong><br><br>\n",
    "\n",
    "\n",
    "<i>KNN Classification</i><br>\n",
    "\n",
    "<strong>Pros</strong><br>\n",
    "- Simple algorithm â€” to explain and understand/interpret. <br>\n",
    "- High accuracy (relatively) â€” it is pretty high but not competitive in comparison to better supervised learning models.It is  providing a accuracy of <strong>76.85%</strong> . \n",
    "\n",
    "<strong>Cons</strong><br> \n",
    "- Computationally expensive â€” because the algorithm stores all of the training data so it takes a lot of time to predict(not train).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "## Challenges and Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The regular expression approach for replacing specific keywords may not work as the data will increase, the cleaning will take more time and regex is not that much scalable. Even for 1 million records it will take days to process it and if it fails we cannot track it properly.\n",
    "- Preparation of the dataframe from the documents should be done properly to ensure no wrong labels.\n",
    "- If the size of the dataset increases then tf-idf method for vectorization will fail because of large matrix size.\n",
    "- Applying K-Fold Cross Validation on the data to find optimum value of K was computationally very intensive because of such large number of features.\n",
    "- Model training can be improved by trying other approaches which are build majorly for text classification and response is fast with a probability of each class label.\n",
    "- If the size increases and tf-idf starts to fail we can use tokenizer with CNN or Word Embedding with CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
